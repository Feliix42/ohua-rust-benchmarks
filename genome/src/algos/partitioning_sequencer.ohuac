ns sequencer;

use sf genome::ohua_sequencer::{reassemble, update_sequence};
use sf crate::{collect_work, create_runtime, generate_iterator_indices, get_overlap, partition, remaining_computations, spawn_onto_pool, spawn_onto_pool2};

fn main(segments: Segments, starting_overlap: usize, threadcount: usize) -> Vec<Nucleotide> {
    // this would be generated
    let rt = create_runtime(threadcount);

    // Phase 1: deduplicate the genome segments
    let deduped = dedup(segments, threadcount, rt);

    // Phase 2: Sequence the genome (parallelism happens here)
    let sequenced = match_segs(deduped, starting_overlap, threadcount, rt);

    // Phase 3: Reassemble the genome
    reassemble(sequenced)
}

// Phase 1
fn dedup(segments: Segments, threadcount: usize, rt: Arc<tokio::runtime::Runtime>) -> Vec<SequencerItem> {
    let parts = partition(segments, threadcount);
    
    // this would normally be a loop, which is now hidden inside the tokio threadpool
    let receivers = spawn_onto_pool2(parts, rt);

    collect_work(receivers)
}

// Phase 2
fn match_segs(seq: Vec<SequencerItem>, overlap: usize, threadcount: usize, rt: Arc<tokio::runtime::Runtime>) -> Vec<SequencerItem> {
    let (o, next) = get_overlap(overlap);

    let indices = generate_iterator_indices(seq, threadcount);

    // threadpool erzeugen und threads spawnen, pool und handles zur√ºck
    let receivers = spawn_onto_pool(indices, overlap, seq, rt);

    // handles collecten, shutdown auf pool callen
    let updates = collect_work(receivers);

    // TODO: Handle failed updates
    // don't care for failed updates for now!
    let updated_data = update_sequence(seq, updates, o);

    if (remaining_computations(next)) {
        match_segs(updated_data, next, threadcount, rt)
    } else {
        updated_data
    }
}
